{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск наиболее точного алгоритма машинного обучения\n",
    "# используем LinearRegression(), RandomForestRegressor, KNeighborsRegressor, SVR\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from pandas import read_csv, DataFrame\n",
    "import array \n",
    "\n",
    "path_to_data  = r\"C:/bauman/git_bauman/data/ebw_data.csv\"\n",
    "\n",
    "dataset = pd.read_csv(path_to_data)\n",
    "dataset.head()\n",
    "dataset.describe()\n",
    "\n",
    "# посмотрели есть ли выпадения данных\n",
    "print('percentage of NaN cells:')\n",
    "print(dataset.isna().sum() / dataset.shape[0] *100)\n",
    "\n",
    "#смотрим корреляцию между столбцами\n",
    "dataset.corr()\n",
    "#особенное какой-то корреляции не видно, максимальная между VW и Width = -0,87 и VW и Depth = -0,67\n",
    "# попробуем разные методы \n",
    "\n",
    "# нормализация и запоминание мин и макс по столбцам\n",
    "# для регрессси не нужно, но нужно для ИНС. Сделаем для общего подхода к решению\n",
    "maxdataset = dataset[['IW','IF','VW','FP','Depth','Width']].max()\n",
    "mindataset = dataset[['IW','IF','VW','FP','Depth','Width']].min()\n",
    "\n",
    "maxIW = maxdataset['IW'] \n",
    "minIW = mindataset['IW'] \n",
    "normIW = (dataset['IW'] - minIW ) / (maxIW - minIW )\n",
    "\n",
    "maxIF = maxdataset['IF'] \n",
    "minIF = mindataset['IF'] \n",
    "normIF = (dataset['IF'] - minIF ) / (maxIF - minIF )\n",
    "\n",
    "maxVW = maxdataset['VW'] \n",
    "minVW = mindataset['VW'] \n",
    "normVW = (dataset['VW'] - minVW ) / (maxVW - minVW )\n",
    "\n",
    "maxFP = maxdataset['FP'] \n",
    "minFP = mindataset['FP'] \n",
    "normFP = (dataset['FP'] - minFP ) / (maxFP - minFP )\n",
    "\n",
    "maxDepth = maxdataset['Depth'] \n",
    "minDepth = mindataset['Depth'] \n",
    "normDepth = (dataset['Depth'] - minDepth ) / (maxDepth - minDepth )\n",
    "\n",
    "maxWidth = maxdataset['Width'] \n",
    "minWidth = mindataset['Width'] \n",
    "normWith = (dataset['Width'] - minWidth ) / (maxWidth - minWidth )\n",
    "\n",
    "# сохраним для случая использования модели отдельно от программы обучения\n",
    "minmax = pd.DataFrame({'maxDepth': maxDepth,\n",
    "                       'minDepth': minDepth,\n",
    "                       'minWidth': minWidth,\n",
    "                       'maxWidth': maxWidth,\n",
    "                       'minIW': minIW,\n",
    "                       'maxIW': maxIW,\n",
    "                       'minIF': minIF,\n",
    "                       'maxIF': maxIF,\n",
    "                       'minVW': minVW,\n",
    "                       'maxVW': maxVW,\n",
    "                       'minFP': minFP,\n",
    "                       'maxFP': maxFP,\n",
    "                        }, index=[0])\n",
    "minmax.to_csv(path_to_model + r'/minmax.csv')\n",
    "\n",
    "#собираем dataset для обучения\n",
    "normdataset = pd.DataFrame({'IW': normIW, \n",
    "                            'IF': normIF,\n",
    "                            'VW': normVW,\n",
    "                            'FP': normFP,\n",
    "                            'Depth': normDepth,\n",
    "                            'Width': normWith,\n",
    "                            })\n",
    "\n",
    "# переменные для входных и выходных данных\n",
    "X = normdataset[['IW','IF','VW','FP']]\n",
    "Y = normdataset[['Depth','Width']] \n",
    "\n",
    "# делим выборку и перемешиваем\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.1, shuffle = True)\n",
    "\n",
    "\n",
    "# создаем набор моделей\n",
    "models_set = [LinearRegression(),  \n",
    "\t          RandomForestRegressor(n_estimators=50, max_features ='sqrt'), \n",
    "\t          KNeighborsRegressor(n_neighbors=6),  \n",
    "\t          SVR(kernel='linear')]\n",
    "\n",
    " \n",
    "TestModels = DataFrame()\n",
    "tmp = {}\n",
    "\n",
    "currR2 = array.array('f',[0.0,0.0])\n",
    "\n",
    "for model in models_set:\n",
    "   \n",
    "    m = str(model)\n",
    "    tmp['Model'] = m[:m.index('(')]    \n",
    "   \n",
    "    for i in  range(Y_train.shape[1]):\n",
    "        model.fit(X_train.values, Y_train.iloc[:,i].values) \n",
    "     \n",
    "        r2 = r2_score(Y_test.iloc[:,i].values, model.predict(X_test.values))\n",
    "        \n",
    "        tmp['R2_Y%s'%str(i+1)] = r2\n",
    "        print(i,\"  -> \",m,\" :  F(IW,IF,VW,FP) vs \",Y_train.columns[i],\" R2_Y\" ,r2)\n",
    "\n",
    "    TestModels  = TestModels.append([tmp])\n",
    " \n",
    "TestModels.set_index('Model', inplace=True)\n",
    "\n",
    "#по результатам тестирования моделей:\n",
    "#R2 не стабилен, возможно слишком сильное влияние разбиения на тренеровочную и тестовую части\n",
    "#R2 менялся от 0,32 до 0,97\n",
    "\n",
    "TestModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели ИНС\n",
    "\n",
    "from pandas import read_csv, DataFrame\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_to_model = r'C:/bauman/git_bauman/ebw_model'\n",
    "path_to_data  = r\"C:/bauman/git_bauman/data/ebw_data.csv\"\n",
    "\n",
    "dataset = pd.read_csv(path_to_data)\n",
    "#dataset.head()\n",
    "#dataset.describe()\n",
    "\n",
    "# посмотрели есть ли выпадения данных\n",
    "print('percentage of NaN cells:')\n",
    "print(dataset.isna().sum() / dataset.shape[0] *100)\n",
    "\n",
    "\n",
    "# нормализация и запоминание мин и макс по столбцам\n",
    "maxdataset = dataset[['IW','IF','VW','FP','Depth','Width']].max()\n",
    "mindataset = dataset[['IW','IF','VW','FP','Depth','Width']].min()\n",
    "\n",
    "maxIW = maxdataset['IW'] \n",
    "minIW = mindataset['IW'] \n",
    "normIW = (dataset['IW'] - minIW ) / (maxIW - minIW )\n",
    "\n",
    "maxIF = maxdataset['IF'] \n",
    "minIF = mindataset['IF'] \n",
    "normIF = (dataset['IF'] - minIF ) / (maxIF - minIF )\n",
    "\n",
    "maxVW = maxdataset['VW'] \n",
    "minVW = mindataset['VW'] \n",
    "normVW = (dataset['VW'] - minVW ) / (maxVW - minVW )\n",
    "\n",
    "maxFP = maxdataset['FP'] \n",
    "minFP = mindataset['FP'] \n",
    "normFP = (dataset['FP'] - minFP ) / (maxFP - minFP )\n",
    "\n",
    "maxDepth = maxdataset['Depth'] \n",
    "minDepth = mindataset['Depth'] \n",
    "normDepth = (dataset['Depth'] - minDepth ) / (maxDepth - minDepth )\n",
    "\n",
    "maxWidth = maxdataset['Width'] \n",
    "minWidth = mindataset['Width'] \n",
    "normWith = (dataset['Width'] - minWidth ) / (maxWidth - minWidth )\n",
    "\n",
    "minmax = pd.DataFrame({'maxDepth': maxDepth,\n",
    "                       'minDepth': minDepth,\n",
    "                       'minWidth': minWidth,\n",
    "                       'maxWidth': maxWidth,\n",
    "                       'minIW': minIW,\n",
    "                       'maxIW': maxIW,\n",
    "                       'minIF': minIF,\n",
    "                       'maxIF': maxIF,\n",
    "                       'minVW': minVW,\n",
    "                       'maxVW': maxVW,\n",
    "                       'minFP': minFP,\n",
    "                       'maxFP': maxFP,\n",
    "                        }, index=[0])\n",
    "minmax.to_csv(path_to_model + r'/minmax.csv')\n",
    "\n",
    "normdataset = pd.DataFrame({'IW': normIW, \n",
    "                            'IF': normIF,\n",
    "                            'VW': normVW,\n",
    "                            'FP': normFP,\n",
    "                            'Depth': normDepth,\n",
    "                            'Width': normWith,\n",
    "                            })\n",
    "\n",
    "# переменные для входных и выходных данных\n",
    "X = normdataset[['IW','IF','VW','FP']]\n",
    "Y = normdataset[['Depth','Width']] \n",
    "\n",
    "# делим выборку и перемешиваем\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.05, shuffle = True)\n",
    "\n",
    "# создаем модель\n",
    "model = Sequential()\n",
    "model.add(Dense(4, activation = 'sigmoid'))\n",
    "model.add(Dense(2, activation = 'sigmoid'))\n",
    "model.compile( loss = 'mse',optimizer = 'adam', metrics = ['accuracy'] )\n",
    "\n",
    "history = model.fit(X_train,Y_train, epochs = 1000, validation_data = (X_train,Y_train), verbose = 1)\n",
    "\n",
    "model.save(path_to_model)\n",
    "\n",
    "# для инфомации выводим кривую обучения\n",
    "plt.plot(history.history['accuracy'],label = 'Обучающая выборка')\n",
    "plt.plot(history.history['val_accuracy'],label = 'Точность тест')\n",
    "plt.title('Обучение')\n",
    "plt.xlabel('эпохи')\n",
    "plt.ylabel(model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: windows-1251\n",
    "# код отвечающий за предсказание с использованием ИНС, будет использован в консольном приложении\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "# путь до сохраненной модели\n",
    "path_to_model = r'C:/bauman/git_bauman/ebw_model'\n",
    "\n",
    "minmax = pd.read_csv(path_to_model + r'/minmax.csv')\n",
    "\n",
    "print(\"Введите параметр IW (сварочный ток), значение между [%3.1f,%3.1f]\" % (minmax.minIW,minmax.maxIW))\n",
    "IW_human_input = input()\n",
    "if IW_human_input=='':\n",
    "    IW_human_input = (minmax.minIW+minmax.maxIW)/2\n",
    "else:\n",
    "    IW_human_input = float(IW_human_input)\n",
    "    \n",
    "print(\"Введите параметр IF (ток фокусировки эл. пучка), значение между [%3.1f,%3.1f]\" % (minmax.minIF,minmax.maxIF))\n",
    "IF_human_input = input()\n",
    "if IF_human_input=='':\n",
    "    IF_human_input = (minmax.minIF+minmax.maxIF)/2\n",
    "else:\n",
    "    IF_human_input = float(IF_human_input)\n",
    "\n",
    "\n",
    "print(\"Введите параметр VW (скорость сварки), значение между [%3.1f,%3.1f]\" % (minmax.minVW,minmax.maxVW))\n",
    "VW_human_input = input()\n",
    "if VW_human_input=='':\n",
    "    VW_human_input = (minmax.minVW+minmax.maxVW)/2\n",
    "else:\n",
    "    VW_human_input = float(VW_human_input)\n",
    "\n",
    "print(\"Введите параметр FP (расстояние до образца), значение между  [%3.1f,%3.1f]\" % (minmax.minFP,minmax.maxFP))\n",
    "FP_human_input = input()\n",
    "if FP_human_input=='':\n",
    "    FP_human_input = (minmax.minFP+minmax.maxFP)/2\n",
    "else:\n",
    "    FP_human_input = float(FP_human_input)\n",
    "\n",
    "    \n",
    "human_input = pd.DataFrame({'IW': [IW_human_input],\n",
    "                            'IF': [IF_human_input],\n",
    "                            'VW': [VW_human_input],\n",
    "                            'FP': [FP_human_input]})\n",
    "\n",
    "human_input['IW'] = (human_input['IW'] - minmax.minIW) / (minmax.maxIW - minmax.minIW)\n",
    "human_input['IF'] = (human_input['IF'] - minmax.minIF) / (minmax.maxIF - minmax.minIF)\n",
    "human_input['VW'] = (human_input['VW'] - minmax.minVW) / (minmax.maxVW - minmax.minVW)\n",
    "human_input['FP'] = (human_input['FP'] - minmax.minFP) / (minmax.maxFP - minmax.minFP)\n",
    "\n",
    "model= keras.models.load_model(path_to_model)\n",
    "\n",
    "mypredcit = model.predict(human_input)\n",
    "Depth = mypredcit[:,0]*(minmax.maxDepth-minmax.minDepth)+minmax.minDepth\n",
    "Width = mypredcit[:,1]*(minmax.maxWidth-minmax.minWidth)+minmax.minWidth\n",
    "\n",
    "predict = pd.DataFrame({'Depth': Depth, \n",
    "                        'Width': Width})\n",
    "\n",
    "print(\"F(IW,IF,Vw,FP) = (Depth, Width)\")\n",
    "print(\"F(%3.1f,%3.1f,%3.1f,%3.1f) = (%3.4f,%3.4f)\"%(IW_human_input,IF_human_input,VW_human_input,FP_human_input,Depth,Width))\n",
    "\n",
    "\n",
    "\n",
    "#print(predict)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2a7dea567aa21acd9bf37b61e73e4ca024b299331bd2a845bcc12904aaa0a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
